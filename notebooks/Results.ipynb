{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook a summary of the best results that have been obtained so far is displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if os.getcwd().endswith('notebooks'):\n",
    "    project_path = os.path.abspath(os.path.join('..'))\n",
    "    if project_path not in sys.path:\n",
    "        sys.path.append(project_path)\n",
    "    os.chdir(os.pardir)\n",
    "\n",
    "from src.models import train\n",
    "from src.models.model_utils import load_dataset, save_model, load_model,\\\n",
    "                            redefine_labels, standardize_per_example\n",
    "from src.models import spectrogram_models\n",
    "from src.models import signal_models\n",
    "from src.models import scalogram_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric used to assess the performance of a model is the F1 score:\n",
    "\n",
    "$$ \\mathrm{F1 score} = 2 \\dfrac{\\mathrm{precision \\cdot recall}}{\\mathrm{precision} + \\mathrm{recall}} $$\n",
    "\n",
    "Here is a summary of the best results so far, extracted from the ```results``` CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model      | Disease | Dataset            | Epochs | Learning rate | Batch size | Train f1 | Dev f1 | Test f1 | Name                            |\n",
    "|------------|---------|--------------------|--------|---------------|------------|----------|--------|---------|---------------------------------|\n",
    "| sig_CNN_1  | als     | signals-dataset    | 300    | 0.0001        | 64         | 0.8887   | 0.7833 | 1.0000  | sig_CNN_1_als_201904201054      |\n",
    "| scal_CNN_1 | control | scalograms-dataset | 300    | 0.0001        | 64         | 1.0000   | 0.9256 | 0.9148  | scal_CNN_1_control_201904201052 |\n",
    "| scal_CNN_1 | hunt    | scalograms-dataset | 300    | 0.0001        | 64         | 0.9980   | 0.8398 | 1.0000  | scal_CNN_1_hunt_201904201042    |\n",
    "| sig_CNN_1  | park    | signals-dataset    | 500    | 0.0001        | 64         | 0.9087   | 0.8978 | 0.0000  | sig_CNN_1_park                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is surprising that in some cases, test performance is better than performance on dev and train sets.\n",
    "\n",
    "However, it should be noted that the test set, which is made up of one patient per disease, might be to small to give an accurate estimate of the models' performance on unseen examples. In fact, if the models shown above are retrained with the same configuration the test performance might not be exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the two architectures that have given the best results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-dimensional convolutional model ```sig_CNN_1```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture takes the normalized (and downsampled) 1D signal segments of length 900."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 891, 32)           352       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 882, 32)           10272     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 294, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 285, 64)           20544     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 276, 64)           41024     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 72,257\n",
      "Trainable params: 72,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visualize models\n",
    "model = signal_models.sig_CNN_1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='img/sig_CNN_1.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a visualization of the model:\n",
    "<img src=\"../img/sig_CNN_1.png\" alt=\"model1D\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-dimensional convolutional model ```scal_CNN_1```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture takes as input the one-channel 100x100 images representing the signal scalogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 100, 32)      832       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 32)          2080      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 432)               124848    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 433       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 384,385\n",
      "Trainable params: 384,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = scalogram_models.scal_CNN_1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='img/scal_CNN_1.png', show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a visualization of the model:\n",
    "<img src=\"../img/scal_CNN_1.png\" alt=\"model2D\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the **conclusions** from these results, as well as from the performance obtained in other experiments, are:\n",
    "\n",
    "1. The 2D convolutional models trained on scalograms (particularly the scal_CNN_1 model) work relatively well for predicting Control and Huntington’s disease.\n",
    "\n",
    "2. The 1D convolutional model trained on signal segments works decently predicting ALS. Its performance is comparable to the same model's performance predicting other classes.\n",
    "\n",
    "3. None of the models trained on spectrograms yields better performance than the models trained on scalograms\n",
    "\n",
    "4. No model right now is able to accurately classify Parkinson’s disease on the test set.\n",
    "\n",
    "5. Training for more epochs does not help performance on test set, it only further overfits the train set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
